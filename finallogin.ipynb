{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5bf841",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ITinframanage\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\ITinframanage\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\speechbrain\\utils\\parameter_transfer.py:234: UserWarning: Requested Pretrainer collection using symlinks on Windows. This might not work; see `LocalStrategy` documentation. Consider unsetting `collect_in` in Pretrainer to avoid symlinking altogether.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select an option:\n",
      "1. Register\n",
      "2. Login\n",
      "3. Exit\n",
      "Recording login audio\n",
      "Recording...\n",
      "Finished recording.\n",
      "0.6929559111595154 ./app/Server/dynamic-content/final_standard/maddula.wav ./app/Server/dynamic-content/unknownVoices/unknown.wav\n",
      "Score for maddula: tensor([0.6930])\n",
      "0.6509189605712891 ./app/Server/dynamic-content/final_standard/sunamdha.wav ./app/Server/dynamic-content/unknownVoices/unknown.wav\n",
      "Score for sunamdha: tensor([0.6509])\n",
      "0.18983744084835052 ./app/Server/dynamic-content/final_standard/pras.wav ./app/Server/dynamic-content/unknownVoices/unknown.wav\n",
      "Score for pras: tensor([0.1898])\n",
      "0.2572924494743347 ./app/Server/dynamic-content/final_standard/sandhya.wav ./app/Server/dynamic-content/unknownVoices/unknown.wav\n",
      "Score for sandhya: tensor([0.2573])\n",
      "0.042848408222198486 ./app/Server/dynamic-content/final_standard/shivam.wav ./app/Server/dynamic-content/unknownVoices/unknown.wav\n",
      "Score for shivam: tensor([0.0428])\n",
      "0.38168904185295105 ./app/Server/dynamic-content/final_standard/ramya.wav ./app/Server/dynamic-content/unknownVoices/unknown.wav\n",
      "Score for ramya: tensor([0.3817])\n",
      "0.34164732694625854 ./app/Server/dynamic-content/final_standard/geetanjali.wav ./app/Server/dynamic-content/unknownVoices/unknown.wav\n",
      "Score for geetanjali: tensor([0.3416])\n",
      "0.06666447222232819 ./app/Server/dynamic-content/final_standard/manik.wav ./app/Server/dynamic-content/unknownVoices/unknown.wav\n",
      "Score for manik: tensor([0.0667])\n",
      "0.058236464858055115 ./app/Server/dynamic-content/final_standard/jasjot.wav ./app/Server/dynamic-content/unknownVoices/unknown.wav\n",
      "Score for jasjot: tensor([0.0582])\n",
      "0.24933256208896637 ./app/Server/dynamic-content/final_standard/an.wav ./app/Server/dynamic-content/unknownVoices/unknown.wav\n",
      "Score for an: tensor([0.2493])\n",
      "Unauthorized user\n",
      "Select an option:\n",
      "1. Register\n",
      "2. Login\n",
      "3. Exit\n",
      "Recording login audio\n",
      "Recording...\n",
      "Finished recording.\n",
      "0.775523841381073 ./app/Server/dynamic-content/final_standard/maddula.wav ./app/Server/dynamic-content/unknownVoices/unknown.wav\n",
      "Score for maddula: tensor([0.7755])\n",
      "0.6969670653343201 ./app/Server/dynamic-content/final_standard/sunamdha.wav ./app/Server/dynamic-content/unknownVoices/unknown.wav\n",
      "Score for sunamdha: tensor([0.6970])\n",
      "0.21653085947036743 ./app/Server/dynamic-content/final_standard/pras.wav ./app/Server/dynamic-content/unknownVoices/unknown.wav\n",
      "Score for pras: tensor([0.2165])\n",
      "0.2980373501777649 ./app/Server/dynamic-content/final_standard/sandhya.wav ./app/Server/dynamic-content/unknownVoices/unknown.wav\n",
      "Score for sandhya: tensor([0.2980])\n",
      "0.08176930248737335 ./app/Server/dynamic-content/final_standard/shivam.wav ./app/Server/dynamic-content/unknownVoices/unknown.wav\n",
      "Score for shivam: tensor([0.0818])\n",
      "0.43318653106689453 ./app/Server/dynamic-content/final_standard/ramya.wav ./app/Server/dynamic-content/unknownVoices/unknown.wav\n",
      "Score for ramya: tensor([0.4332])\n",
      "0.39715325832366943 ./app/Server/dynamic-content/final_standard/geetanjali.wav ./app/Server/dynamic-content/unknownVoices/unknown.wav\n",
      "Score for geetanjali: tensor([0.3972])\n",
      "0.09508402645587921 ./app/Server/dynamic-content/final_standard/manik.wav ./app/Server/dynamic-content/unknownVoices/unknown.wav\n",
      "Score for manik: tensor([0.0951])\n",
      "0.16513456404209137 ./app/Server/dynamic-content/final_standard/jasjot.wav ./app/Server/dynamic-content/unknownVoices/unknown.wav\n",
      "Score for jasjot: tensor([0.1651])\n",
      "0.22940829396247864 ./app/Server/dynamic-content/final_standard/an.wav ./app/Server/dynamic-content/unknownVoices/unknown.wav\n",
      "Score for an: tensor([0.2294])\n",
      "Welcome maddula to OTA Voice Assistant\n",
      "Listening for a wake word: 'Hey Bike'\n",
      "Recording...\n",
      "Finished recording.\n",
      "Recognized keyword: hey bike\n",
      "How can I help you?\n",
      "Recording...\n",
      "Finished recording.\n",
      "User command: can you tell a suggest shortest route\n",
      " Direct score = 0.7105 | Threshold = 0.597100019454956\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step\n",
      "Anirban ➤ Main: Cloud, Sub: Traffic/Maps\n",
      "Sunamdha ➤ Main: Cloud, Sub: Traffic/Maps\n",
      "Command recoginized as Cloud with subcategory Traffic/Maps\n",
      "Listening for a wake word: 'Hey Bike'\n",
      "Recording...\n",
      "Finished recording.\n",
      "Recognized keyword: bike\n",
      "Unrecognized command. Please say 'Logout' to exit the session.\n",
      "Listening for a wake word: 'Hey Bike'\n",
      "Recording...\n",
      "Finished recording.\n",
      "Recognized keyword: logout\n",
      "Logging out. Goodbye!\n",
      "Select an option:\n",
      "1. Register\n",
      "2. Login\n",
      "3. Exit\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ITinframanage\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pyaudio\n",
    "#import sounddevice as sd\n",
    "import wave\n",
    "import numpy as np\n",
    "import time\n",
    "import scipy.io.wavfile as wav\n",
    "import pyttsx3\n",
    "import torch\n",
    "from time import sleep\n",
    "import speech_recognition as sr\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from speechbrain.inference.speaker import SpeakerRecognition\n",
    "from pydub import AudioSegment\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"sklearn\")\n",
    "\n",
    "\n",
    "#app/Server/pretrained_models/spkrec-ecapa-voxceleb\n",
    "verification = SpeakerRecognition.from_hparams(source=\"speechbrain/spkrec-ecapa-voxceleb\", savedir=\"app/Server/pretrained_models/spkrec-ecapa-voxceleb\")\n",
    "# --- Model Loading ---\n",
    "model = joblib.load('./app/Server/anirbanModels/Main/RNN_Multiclass_Subclass.joblib')\n",
    "tokenizer = joblib.load('./app/Server/anirbanModels/Main/tokenizert.joblib')\n",
    "max_sequence_length = joblib.load('./app/Server/anirbanModels/Main/max_sequence_length_mainModel.joblib')\n",
    "\n",
    "model_E = joblib.load('./app/Server/anirbanModels/Edge/RNN_Multiclass_SubclassCategory.joblib')\n",
    "tokenizer_E = joblib.load('./app/Server/anirbanModels/Edge/tokenizer.joblib')\n",
    "max_sequence_length_E = joblib.load('./app/Server/anirbanModels/Edge/max_sequence_length.joblib')\n",
    "\n",
    "model_C = joblib.load('./app/Server/anirbanModels/Cloud/RNN_Multiclass_SubclassCategory.joblib')\n",
    "tokenizer_C = joblib.load('./app/Server/anirbanModels/Cloud/tokenizer.joblib')\n",
    "max_sequence_length_C = joblib.load('./app/Server/anirbanModels/Cloud/max_sequence_length.joblib')\n",
    "\n",
    "model_U = joblib.load('./app/Server/anirbanModels/Update/RNN_Multiclass_SubclassCategory.joblib')\n",
    "tokenizer_U = joblib.load('./app/Server/anirbanModels/Update/tokenizer.joblib')\n",
    "max_sequence_length_U = joblib.load('./app/Server/anirbanModels/Update/max_sequence_length.joblib')\n",
    "\n",
    "\n",
    "# Initialize the speech engine\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "def speak(text):\n",
    "    print(text)\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "def record_audio(file_path, duration=10, audioName=\"None\"):\n",
    "    CHUNK = 1024\n",
    "    FORMAT = pyaudio.paInt16\n",
    "    CHANNELS = 2\n",
    "    RATE = 48000\n",
    "    RECORD_SECONDS = duration\n",
    "    WAVE_OUTPUT_FILENAME = file_path\n",
    "    audio = pyaudio.PyAudio()\n",
    "    stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                        rate=RATE, input=True,\n",
    "                        frames_per_buffer=CHUNK)\n",
    "   \n",
    "       \n",
    "   \n",
    "    if(audioName==\"HeyTvs\"):\n",
    "        speak(\"Please say the wake word 'Hey TVS'\")\n",
    "        sleep(2)\n",
    "    print(\"Recording...\")\n",
    "    frames = []\n",
    "    for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "    print(\"Finished recording.\")\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "    wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "    wf.setnchannels(CHANNELS)\n",
    "    wf.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "    wf.setframerate(RATE)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "\n",
    "\n",
    "\n",
    "def transcribe_google(audio_path):\n",
    "    r = sr.Recognizer()\n",
    "    with sr.AudioFile(audio_path) as source:\n",
    "        audio = r.record(source)\n",
    "\n",
    "    try:\n",
    "        text = r.recognize_google(audio)\n",
    "        return text.strip().lower()\n",
    "    except sr.UnknownValueError:\n",
    "        return \"could not understand audio\"\n",
    "    except sr.RequestError as e:\n",
    "        return f\"could not request results; {e}\"\n",
    "\n",
    "\n",
    "# Predict helper\n",
    "def predict_class(command, tokenizer, model, max_sequence_length):\n",
    "    sequence = tokenizer.texts_to_sequences([command])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=max_sequence_length, padding='post')\n",
    "    prediction = model.predict(padded_sequence)\n",
    "    return np.argmax(prediction)\n",
    "\n",
    "def Edge_Model(_, command, model, tokenizer, max_sequence_length):\n",
    "    prediction = predict_class(command, tokenizer, model, max_sequence_length)\n",
    "    return [\"Battery Fuel\", \"Tires\", \"Greetings\", \"Basic\"][prediction] if prediction < 4 else \"Unknown\"\n",
    "\n",
    "def Cloud_Model(_, command, model, tokenizer, max_sequence_length):\n",
    "    prediction = predict_class(command, tokenizer, model, max_sequence_length)\n",
    "    return [\"Song Media\", \"News Notification\", \"Weather\", \"Traffic Maps\"][prediction] if prediction < 4 else \"Unknown\"\n",
    "\n",
    "def Update_Model(_, command, model, tokenizer, max_sequence_length):\n",
    "    prediction = predict_class(command, tokenizer, model, max_sequence_length)\n",
    "    return [\"Cancel\", \"Perform\", \"Check\"][prediction] if prediction < 3 else \"Unknown\"\n",
    "\n",
    "def Main_model(_, command):\n",
    "    prediction = predict_class(command, tokenizer, model, max_sequence_length)\n",
    "    if prediction == 0:\n",
    "        return [\"Edge\", Edge_Model(_, command, model_E, tokenizer_E, max_sequence_length_E)]\n",
    "    elif prediction == 1:\n",
    "        return [\"Cloud\", Cloud_Model(_, command, model_C, tokenizer_C, max_sequence_length_C)]\n",
    "    elif prediction == 2:\n",
    "        return [\"Update\", Update_Model(_, command, model_U, tokenizer_U, max_sequence_length_U)]\n",
    "    elif prediction == 3:\n",
    "        return [\"Miscellaneous\", \"Temporary\"]\n",
    "    return [\"Unknown\", \"Unknown\"]\n",
    "\n",
    "def sunamdha(command):\n",
    "    pipeline = joblib.load('./app/Server/Models/ClassSvm.joblib')\n",
    "    df = pd.DataFrame({'Commands': [command]})\n",
    "    return pipeline.predict(df['Commands'])[0]\n",
    "\n",
    "def commandClassify_Sunamdha(class_label_to_predict, text_result):\n",
    "    df = pd.DataFrame({'Commands': [text_result]})\n",
    "    if class_label_to_predict in ['Miscellaneous']:\n",
    "        predicted_subclass = ['Temporary']\n",
    "    elif class_label_to_predict in ['Not needed']:\n",
    "        predicted_subclass = ['NC']\n",
    "    else:\n",
    "        model_path = f'./app/Server/Models/SubClassModel_{class_label_to_predict}.joblib'\n",
    "        subClassModel = joblib.load(model_path)\n",
    "        predicted_subclass = subClassModel.predict(df['Commands'])\n",
    "    return [class_label_to_predict, predicted_subclass[0]]\n",
    "\n",
    "def commandClassifier(command):\n",
    "    subclasscat = \"MAINMODEL\"\n",
    "    opLst = Main_model(subclasscat, command)\n",
    "    subclass_cat = commandClassify_Sunamdha(opLst[0], command)\n",
    "    return [opLst[0], subclass_cat[1], 0, 0]  # timing skipped for simplicity\n",
    "def SRSR(username, command_file):\n",
    "    try:\n",
    "        dyn_thre = None\n",
    "        with open(\"app/Server/dynamic-content/dynamicThreshold.txt\", \"r\") as f:\n",
    "            for line in f:\n",
    "                uname, value = line.strip().split(\": \")\n",
    "                if uname == username:\n",
    "                    dyn_thre = torch.tensor(float(value.replace('tensor([', '').replace('])', '')))\n",
    "                    break\n",
    "\n",
    "        if dyn_thre is None:\n",
    "            print(\"Dynamic threshold not found for user.\")\n",
    "            return False\n",
    "\n",
    "        ref_path = None\n",
    "        with open(\"app/Server/dynamic-content/users.txt\", \"r\") as f:\n",
    "            for line in f:\n",
    "                uname, path = line.strip().split(\": \")\n",
    "                if uname == username:\n",
    "                    ref_path = path.strip()\n",
    "                    break\n",
    "\n",
    "        if not ref_path or not os.path.exists(ref_path):\n",
    "            print(\"Reference file not found.\")\n",
    "            return False\n",
    "\n",
    "        # Step 1 - Direct verification\n",
    "        ref_path=ref_path.replace(\"\\\\\", \"/\")\n",
    "        score, _ = verification.verify_files(ref_path, command_file)\n",
    "        score = score.item()\n",
    "        print(f\" Direct score = {score:.4f} | Threshold = {dyn_thre}\")\n",
    "\n",
    "        if score >= dyn_thre:\n",
    "            return True\n",
    "        elif score < 0.3:\n",
    "            print(\"Score too low (< 0.3). Rejecting.\")\n",
    "            return False\n",
    "        else:\n",
    "            # Step 2 - Try wake-word merged verification\n",
    "            wake_path = f\"./app/Server/dynamic-content/heyTVS/{username}_heyTVS.wav\"\n",
    "            if os.path.exists(wake_path):\n",
    "                user_audio = AudioSegment.from_wav(wake_path)\n",
    "                cmd_audio = AudioSegment.from_wav(command_file)\n",
    "                merged = user_audio + cmd_audio\n",
    "                merged_path = \"./app/Server/dynamic-content/unknownVoices/merged_audio_heyTVS.wav\"\n",
    "                merged.export(merged_path, format=\"wav\")\n",
    "\n",
    "                score2, _ = verification.verify_files(ref_path, merged_path)\n",
    "                score2 = score2.item()\n",
    "                print(f\" Merged score = {score2:.4f}\")\n",
    "\n",
    "                if score2 >= dyn_thre or score2 >= 0.7:\n",
    "                    return True\n",
    "                else:\n",
    "                    return False\n",
    "            else:\n",
    "                print(\"Wake word audio not found.\")\n",
    "                return False\n",
    "    except Exception as e:\n",
    "        print(f\"Error in SRSR: {e}\")\n",
    "        return False\n",
    "def register():\n",
    "    # Base paths\n",
    "    base_path = \"./app/Server/dynamic-content\"\n",
    "    users_file_path = os.path.join(base_path, \"users.txt\")\n",
    "    names_file_path = os.path.join(base_path, \"names.txt\")\n",
    "    standard_path = os.path.join(base_path, \"final_standard\")\n",
    "    predict_temp_path = os.path.join(base_path, \"predictTemp\")\n",
    "\n",
    "    # Wake word paths\n",
    "    wake_path = os.path.join(base_path, \"heyTVS\")\n",
    "    wake_file_path = os.path.join(base_path, \"heyTVS.txt\")\n",
    "\n",
    "    # Command paths\n",
    "    command_folder_path = os.path.join(base_path, \"commands\")\n",
    "    command_text_file = os.path.join(base_path, \"commands.txt\")\n",
    "\n",
    "    # Threshold log path\n",
    "    threshold_file_path = os.path.join(base_path, \"dynamicThreshold.txt\")\n",
    "\n",
    "    # Get username\n",
    "    speak(\"Please say your name\")\n",
    "    username = input(\"Enter username: \").strip()\n",
    "\n",
    "    if not username:\n",
    "        speak(\"Username cannot be empty\")\n",
    "        return\n",
    "\n",
    "    # Check if name already exists\n",
    "    if os.path.exists(names_file_path):\n",
    "        with open(names_file_path, \"r\") as file:\n",
    "            existing_names = [line.strip().lower() for line in file]\n",
    "        if username.lower() in existing_names:\n",
    "            speak(\"Username already exists. Please try a different name.\")\n",
    "            return\n",
    "\n",
    "    # File paths\n",
    "    user_audio_path = os.path.join(standard_path, f\"{username}.wav\")\n",
    "    user_audio_predict_path = os.path.join(predict_temp_path, f\"{username}_predict.wav\")\n",
    "    wake_audio_filename = f\"{username}_heyTVS.wav\"\n",
    "    wake_audio_path = os.path.join(wake_path, wake_audio_filename)\n",
    "    command_audio_filename = f\"{username}_command.wav\"\n",
    "    command_audio_path = os.path.join(command_folder_path, command_audio_filename)\n",
    "    relative_wake_path = f\"dynamic-content/heyTVS/{wake_audio_filename}\"\n",
    "    relative_command_path = f\"app/Server/dynamic-content/commands/{command_audio_filename}\"\n",
    "\n",
    "    # Record reference and verification audio\n",
    "    speak(\"Recording reference audio\")\n",
    "    sleep(1)\n",
    "    record_audio(user_audio_path)\n",
    "\n",
    "    speak(\"Recording verification audio\")\n",
    "    sleep(1)\n",
    "    record_audio(user_audio_predict_path)\n",
    "\n",
    "    try:\n",
    "        score, _ = verification.verify_files(user_audio_path, user_audio_predict_path)\n",
    "        score = score.item()\n",
    "        print(user_audio_path, user_audio_predict_path)\n",
    "        print(f\"Verification score: {score:.4f}\")\n",
    "\n",
    "        if score >= 0.7:\n",
    "            # Save reference and name info\n",
    "            with open(users_file_path, \"a\") as ufile:\n",
    "                \n",
    "                ufile.write(f\"{username}: {user_audio_path}\\n\")\n",
    "            with open(names_file_path, \"a\") as nfile:\n",
    "                nfile.write(f\"{username}\\n\")\n",
    "\n",
    "            # Record wake word\n",
    "            record_audio(wake_audio_path, duration=2, audioName=\"HeyTvs\")\n",
    "            with open(wake_file_path, \"a\") as wfile:\n",
    "                wfile.write(f\"{username}: {relative_wake_path}\\n\")\n",
    "\n",
    "            # Record and verify standard command\n",
    "            command_attempts = 0\n",
    "            max_attempts = 8\n",
    "            command_verified = False\n",
    "\n",
    "            while command_attempts < max_attempts and not command_verified:\n",
    "                speak(\"Please say the standard command: 'Current weather in Bangalore is very nice?'\")\n",
    "                sleep(1)\n",
    "                record_audio(command_audio_path, duration=5)\n",
    "\n",
    "                try:\n",
    "                    cmd_score, _ = verification.verify_files(user_audio_path, command_audio_path)\n",
    "                    cmd_score = cmd_score.item()\n",
    "                    print(f\"Command match score: {cmd_score:.4f}\")\n",
    "\n",
    "                    if 0.475 <= cmd_score <= 0.6:\n",
    "                        with open(command_text_file, \"a\") as cfile:\n",
    "                            cfile.write(f\"{username}: {relative_command_path}\\n\")\n",
    "\n",
    "                        # Save threshold score\n",
    "                        with open(threshold_file_path, \"a\") as tfile:\n",
    "                            tfile.write(f\"{username}: tensor([{cmd_score:.4f}])\\n\")\n",
    "\n",
    "                        command_verified = True\n",
    "                        speak(f\"Registration successful for {username}\")\n",
    "                        break\n",
    "                    else:\n",
    "                        speak(\"Command does not match. Please try again.\")\n",
    "                        command_attempts += 1\n",
    "\n",
    "                except Exception as e:\n",
    "                    speak(f\"Error verifying standard command: {str(e)}\")\n",
    "                    command_attempts += 1\n",
    "\n",
    "            if not command_verified:\n",
    "                speak(\"Registration failed due to repeated command mismatch. Cleaning up.\")\n",
    "                cleanup_user_data(username, [\n",
    "                    user_audio_path,\n",
    "                    user_audio_predict_path,\n",
    "                    wake_audio_path,\n",
    "                    command_audio_path\n",
    "                ], [\n",
    "                    users_file_path,\n",
    "                    names_file_path,\n",
    "                    wake_file_path,\n",
    "                    command_text_file,\n",
    "                    threshold_file_path\n",
    "                ])\n",
    "\n",
    "        else:\n",
    "            speak(\"Voice match failed. Registration unsuccessful.\")\n",
    "            if os.path.exists(user_audio_path):\n",
    "                os.remove(user_audio_path)\n",
    "            if os.path.exists(user_audio_predict_path):\n",
    "                os.remove(user_audio_predict_path)\n",
    "\n",
    "    except Exception as e:\n",
    "        speak(f\"Error during registration: {str(e)}\")\n",
    "        if os.path.exists(user_audio_path):\n",
    "            os.remove(user_audio_path)\n",
    "        if os.path.exists(user_audio_predict_path):\n",
    "            os.remove(user_audio_predict_path)\n",
    "\n",
    "# Helper: Remove user entries and files\n",
    "def cleanup_user_data(username, file_paths, text_files):\n",
    "    for file_path in file_paths:\n",
    "        if os.path.exists(file_path):\n",
    "            os.remove(file_path)\n",
    "\n",
    "    def remove_line(file, key):\n",
    "        if os.path.exists(file):\n",
    "            with open(file, \"r\") as f:\n",
    "                lines = f.readlines()\n",
    "            with open(file, \"w\") as f:\n",
    "                for line in lines:\n",
    "                    if not line.lower().startswith(key.lower()):\n",
    "                        f.write(line)\n",
    "\n",
    "    for txt_file in text_files:\n",
    "        remove_line(txt_file, username)\n",
    "\n",
    "\n",
    "def login():\n",
    "    user_file_path = \"./app/Server/dynamic-content/users.txt\"\n",
    "    speak(\"Recording login audio\")\n",
    "    sleep(1)\n",
    "    record_audio(\"./app/Server/dynamic-content/unknownVoices/unknown.wav\")\n",
    "\n",
    "    user_scores = {}\n",
    "    if not os.path.exists(user_file_path):\n",
    "        speak(\"User reference file not found.\")\n",
    "        return\n",
    "\n",
    "    with open(user_file_path, \"r\") as file:\n",
    "        for line in file:\n",
    "            if ':' in line:\n",
    "                name, ref_path = line.strip().split(':', 1)\n",
    "                name, ref_path = name.strip(), ref_path.strip()\n",
    "                if os.path.exists(ref_path):\n",
    "                    try:\n",
    "                        ref_path=ref_path.replace(\"\\\\\", \"/\")\n",
    "                        score, _ = verification.verify_files(ref_path, \"./app/Server/dynamic-content/unknownVoices/unknown.wav\")\n",
    "                        x=\"./app/Server/dynamic-content/unknownVoices/unknown.wav\"\n",
    "                        print(score.item(),ref_path,x)\n",
    "                        user_scores[name] = score.item()\n",
    "                        print(f\"Score for {name}: {score}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing {name}: {e}\")\n",
    "                else:\n",
    "                    print(f\"Reference audio not found for {name}: {ref_path}\")\n",
    "\n",
    "    if user_scores:\n",
    "        best_match = max(user_scores, key=user_scores.get)\n",
    "        max_score = user_scores[best_match]\n",
    "\n",
    "        if max_score >= 0.7:\n",
    "            speak(f\"Welcome {best_match} to OTA Voice Assistant\")\n",
    "            while True:\n",
    "                speak(\"Listening for a wake word: 'Hey Bike'\")\n",
    "                record_audio(\"temp_trigger.wav\", duration=3)\n",
    "                keyword = transcribe_google(\"temp_trigger.wav\")\n",
    "                print(f\"Recognized keyword: {keyword}\")\n",
    "\n",
    "                if \"logout\" in keyword:\n",
    "                    speak(\"Logging out. Goodbye!\")\n",
    "                    break\n",
    "\n",
    "                elif \"hey bike\" in keyword:\n",
    "                    speak(\"How can I help you?\")\n",
    "                    input_cmd_path = \"./app/Server/dynamic-content/inputCmd/inputCmd.wav\"\n",
    "                    record_audio(input_cmd_path, duration=5)\n",
    "                    command = transcribe_google(input_cmd_path)\n",
    "                    print(f\"User command: {command}\")\n",
    "\n",
    "                    # ✅ Verify speaker before classification\n",
    "                    if SRSR(best_match, input_cmd_path):\n",
    "                        # LSTM Prediction\n",
    "                        anirban_main, anirban_sub, _, _ = commandClassifier(command)\n",
    "                        print(f\"Anirban ➤ Main: {anirban_main}, Sub: {anirban_sub}\")\n",
    "\n",
    "                        # SVM Prediction\n",
    "                        svm_main = sunamdha(command)\n",
    "                        svm_main, svm_sub = commandClassify_Sunamdha(anirban_main, command)\n",
    "                        print(f\"Sunamdha ➤ Main: {svm_main}, Sub: {svm_sub}\")\n",
    "\n",
    "                        speak(f\"Command recoginized as {anirban_main} with subcategory {svm_sub}\")\n",
    "                    else:\n",
    "                        speak(\"Speaker verification failed. Please say 'Hey Bike' again.\")\n",
    "                else:\n",
    "                    speak(\"Unrecognized command. Please say 'Logout' to exit the session.\")\n",
    "        else:\n",
    "            speak(\"Unauthorized user\")\n",
    "    else:\n",
    "        speak(\"No valid users found for verification\")\n",
    "\n",
    "def main():\n",
    "    print(\"Select an option:\")\n",
    "    print(\"1. Register\")\n",
    "    print(\"2. Login\")\n",
    "    print(\"3. Exit\")\n",
    "   \n",
    "    choice = input(\"Enter your choice (1/2/3): \")\n",
    "\n",
    "    switch = {\n",
    "        \"1\": register,\n",
    "        \"2\": login,\n",
    "        \"3\":  lambda: (_ for _ in ()).throw(SystemExit)\n",
    "    }\n",
    "\n",
    "    action = switch.get(choice)\n",
    "   \n",
    "    if action:\n",
    "        action()\n",
    "    else:\n",
    "        print(\"Invalid choice. Please select 1 or 2.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    while(1):\n",
    "        main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65eb76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "c=int(input())\n",
    "for i in range(c, c+5):\n",
    "    file_path = f\"HeyTVSWakeword/sunamdha/{i}.wav\"\n",
    "    record_audio(file_path, duration=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "122f23ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ITinframanage\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\speechbrain\\utils\\parameter_transfer.py:234: UserWarning: Requested Pretrainer collection using symlinks on Windows. This might not work; see `LocalStrategy` documentation. Consider unsetting `collect_in` in Pretrainer to avoid symlinking altogether.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select an option:\n",
      "1. Register\n",
      "2. Login\n",
      "3. Exit\n",
      "Recording login audio\n",
      "Recording...\n",
      "Finished recording.\n",
      "0.6872966289520264 ./app/Server/dynamic-content/final_standard/maddula.wav ./app/Server/dynamic-content/unknownVoices/unknown.wav\n",
      "Score for maddula: tensor([0.6873])\n",
      "0.6456663012504578 ./app/Server/dynamic-content/final_standard/sunamdha.wav ./app/Server/dynamic-content/unknownVoices/unknown.wav\n",
      "Score for sunamdha: tensor([0.6457])\n",
      "0.19018082320690155 ./app/Server/dynamic-content/final_standard/pras.wav ./app/Server/dynamic-content/unknownVoices/unknown.wav\n",
      "Score for pras: tensor([0.1902])\n",
      "0.2291005253791809 ./app/Server/dynamic-content/final_standard/sandhya.wav ./app/Server/dynamic-content/unknownVoices/unknown.wav\n",
      "Score for sandhya: tensor([0.2291])\n",
      "0.10770078003406525 ./app/Server/dynamic-content/final_standard/shivam.wav ./app/Server/dynamic-content/unknownVoices/unknown.wav\n",
      "Score for shivam: tensor([0.1077])\n",
      "0.38387563824653625 ./app/Server/dynamic-content/final_standard/ramya.wav ./app/Server/dynamic-content/unknownVoices/unknown.wav\n",
      "Score for ramya: tensor([0.3839])\n",
      "0.2899143099784851 ./app/Server/dynamic-content/final_standard/geetanjali.wav ./app/Server/dynamic-content/unknownVoices/unknown.wav\n",
      "Score for geetanjali: tensor([0.2899])\n",
      "0.05344483256340027 ./app/Server/dynamic-content/final_standard/manik.wav ./app/Server/dynamic-content/unknownVoices/unknown.wav\n",
      "Score for manik: tensor([0.0534])\n",
      "0.12361780554056168 ./app/Server/dynamic-content/final_standard/jasjot.wav ./app/Server/dynamic-content/unknownVoices/unknown.wav\n",
      "Score for jasjot: tensor([0.1236])\n",
      "0.16862435638904572 ./app/Server/dynamic-content/final_standard/an.wav ./app/Server/dynamic-content/unknownVoices/unknown.wav\n",
      "Score for an: tensor([0.1686])\n",
      "Unauthorized user\n",
      "Select an option:\n",
      "1. Register\n",
      "2. Login\n",
      "3. Exit\n",
      "Recording login audio\n",
      "Recording...\n",
      "Finished recording.\n",
      "0.7128708958625793 ./app/Server/dynamic-content/final_standard/maddula.wav ./app/Server/dynamic-content/unknownVoices/unknown.wav\n",
      "Score for maddula: tensor([0.7129])\n",
      "0.6244535446166992 ./app/Server/dynamic-content/final_standard/sunamdha.wav ./app/Server/dynamic-content/unknownVoices/unknown.wav\n",
      "Score for sunamdha: tensor([0.6245])\n",
      "0.2113090306520462 ./app/Server/dynamic-content/final_standard/pras.wav ./app/Server/dynamic-content/unknownVoices/unknown.wav\n",
      "Score for pras: tensor([0.2113])\n",
      "0.2170916199684143 ./app/Server/dynamic-content/final_standard/sandhya.wav ./app/Server/dynamic-content/unknownVoices/unknown.wav\n",
      "Score for sandhya: tensor([0.2171])\n",
      "0.09111955761909485 ./app/Server/dynamic-content/final_standard/shivam.wav ./app/Server/dynamic-content/unknownVoices/unknown.wav\n",
      "Score for shivam: tensor([0.0911])\n",
      "0.40890881419181824 ./app/Server/dynamic-content/final_standard/ramya.wav ./app/Server/dynamic-content/unknownVoices/unknown.wav\n",
      "Score for ramya: tensor([0.4089])\n",
      "0.3476327061653137 ./app/Server/dynamic-content/final_standard/geetanjali.wav ./app/Server/dynamic-content/unknownVoices/unknown.wav\n",
      "Score for geetanjali: tensor([0.3476])\n",
      "0.09884589910507202 ./app/Server/dynamic-content/final_standard/manik.wav ./app/Server/dynamic-content/unknownVoices/unknown.wav\n",
      "Score for manik: tensor([0.0988])\n",
      "0.13528573513031006 ./app/Server/dynamic-content/final_standard/jasjot.wav ./app/Server/dynamic-content/unknownVoices/unknown.wav\n",
      "Score for jasjot: tensor([0.1353])\n",
      "0.18563902378082275 ./app/Server/dynamic-content/final_standard/an.wav ./app/Server/dynamic-content/unknownVoices/unknown.wav\n",
      "Score for an: tensor([0.1856])\n",
      "Welcome maddula to OTA Voice Assistant\n",
      "Listening for a wake word: 'Hey Bike'\n",
      "Recording...\n",
      "Finished recording.\n",
      "Recognized keyword: could not understand audio\n",
      "Unrecognized command. Please say 'Logout' to exit the session.\n",
      "Listening for a wake word: 'Hey Bike'\n",
      "Recording...\n",
      "Finished recording.\n",
      "Recognized keyword: hey bike\n",
      "How can I help you?\n",
      "Recording...\n",
      "Finished recording.\n",
      "User command: can you show me the shortest route to hyderabad\n",
      " Direct score = 0.7393 | Threshold = 0.597100019454956\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step\n",
      "Anirban ➤ Main: Cloud, Sub: Traffic/Maps\n",
      "Sunamdha ➤ Main: Cloud, Sub: Traffic/Maps\n",
      "Command recoginized as Cloud with subcategory Traffic/Maps\n",
      "Listening for a wake word: 'Hey Bike'\n",
      "Recording...\n",
      "Finished recording.\n",
      "Recognized keyword: logout\n",
      "Logging out. Goodbye!\n",
      "Select an option:\n",
      "1. Register\n",
      "2. Login\n",
      "3. Exit\n",
      "Please say your name\n",
      "Recording reference audio\n",
      "Recording...\n",
      "Finished recording.\n",
      "Recording verification audio\n",
      "Recording...\n",
      "Finished recording.\n",
      "./app/Server/dynamic-content\\final_standard\\sai.wav ./app/Server/dynamic-content\\predictTemp\\sai_predict.wav\n",
      "Verification score: 0.8719\n",
      "Please say the wake word 'Hey TVS'\n",
      "Recording...\n",
      "Finished recording.\n",
      "Please say the command: 'Current weather in Bangalore is very nice?'\n",
      "Recording...\n",
      "Finished recording.\n",
      "Command match score: 0.7592\n",
      "Command does not match. Retrying with adjusted prompt...\n",
      "Please say the command: 'Weather in Bangalore'\n",
      "Recording...\n",
      "Finished recording.\n",
      "Command match score: 0.4801\n",
      "Registration successful for sai\n",
      "Select an option:\n",
      "1. Register\n",
      "2. Login\n",
      "3. Exit\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ITinframanage\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pyaudio\n",
    "#import sounddevice as sd\n",
    "import wave\n",
    "import numpy as np\n",
    "import time\n",
    "import scipy.io.wavfile as wav\n",
    "import pyttsx3\n",
    "import torch\n",
    "from time import sleep\n",
    "import speech_recognition as sr\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from speechbrain.inference.speaker import SpeakerRecognition\n",
    "from pydub import AudioSegment\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"sklearn\")\n",
    "\n",
    "\n",
    "#app/Server/pretrained_models/spkrec-ecapa-voxceleb\n",
    "verification = SpeakerRecognition.from_hparams(source=\"speechbrain/spkrec-ecapa-voxceleb\", savedir=\"app/Server/pretrained_models/spkrec-ecapa-voxceleb\")\n",
    "# --- Model Loading ---\n",
    "model = joblib.load('./app/Server/anirbanModels/Main/RNN_Multiclass_Subclass.joblib')\n",
    "tokenizer = joblib.load('./app/Server/anirbanModels/Main/tokenizert.joblib')\n",
    "max_sequence_length = joblib.load('./app/Server/anirbanModels/Main/max_sequence_length_mainModel.joblib')\n",
    "\n",
    "model_E = joblib.load('./app/Server/anirbanModels/Edge/RNN_Multiclass_SubclassCategory.joblib')\n",
    "tokenizer_E = joblib.load('./app/Server/anirbanModels/Edge/tokenizer.joblib')\n",
    "max_sequence_length_E = joblib.load('./app/Server/anirbanModels/Edge/max_sequence_length.joblib')\n",
    "\n",
    "model_C = joblib.load('./app/Server/anirbanModels/Cloud/RNN_Multiclass_SubclassCategory.joblib')\n",
    "tokenizer_C = joblib.load('./app/Server/anirbanModels/Cloud/tokenizer.joblib')\n",
    "max_sequence_length_C = joblib.load('./app/Server/anirbanModels/Cloud/max_sequence_length.joblib')\n",
    "\n",
    "model_U = joblib.load('./app/Server/anirbanModels/Update/RNN_Multiclass_SubclassCategory.joblib')\n",
    "tokenizer_U = joblib.load('./app/Server/anirbanModels/Update/tokenizer.joblib')\n",
    "max_sequence_length_U = joblib.load('./app/Server/anirbanModels/Update/max_sequence_length.joblib')\n",
    "\n",
    "\n",
    "# Initialize the speech engine\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "def speak(text):\n",
    "    print(text)\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "def record_audio(file_path, duration=10, audioName=\"None\"):\n",
    "    CHUNK = 1024\n",
    "    FORMAT = pyaudio.paInt16\n",
    "    CHANNELS = 2\n",
    "    RATE = 48000\n",
    "    RECORD_SECONDS = duration\n",
    "    WAVE_OUTPUT_FILENAME = file_path\n",
    "    audio = pyaudio.PyAudio()\n",
    "    stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                        rate=RATE, input=True,\n",
    "                        frames_per_buffer=CHUNK)\n",
    "   \n",
    "       \n",
    "   \n",
    "    if(audioName==\"HeyTvs\"):\n",
    "        speak(\"Please say the wake word 'Hey TVS'\")\n",
    "        sleep(2)\n",
    "    print(\"Recording...\")\n",
    "    frames = []\n",
    "    for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "    print(\"Finished recording.\")\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "    wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "    wf.setnchannels(CHANNELS)\n",
    "    wf.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "    wf.setframerate(RATE)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "\n",
    "\n",
    "\n",
    "def transcribe_google(audio_path):\n",
    "    r = sr.Recognizer()\n",
    "    with sr.AudioFile(audio_path) as source:\n",
    "        audio = r.record(source)\n",
    "\n",
    "    try:\n",
    "        text = r.recognize_google(audio)\n",
    "        return text.strip().lower()\n",
    "    except sr.UnknownValueError:\n",
    "        return \"could not understand audio\"\n",
    "    except sr.RequestError as e:\n",
    "        return f\"could not request results; {e}\"\n",
    "\n",
    "\n",
    "# Predict helper\n",
    "def predict_class(command, tokenizer, model, max_sequence_length):\n",
    "    sequence = tokenizer.texts_to_sequences([command])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=max_sequence_length, padding='post')\n",
    "    prediction = model.predict(padded_sequence)\n",
    "    return np.argmax(prediction)\n",
    "\n",
    "def Edge_Model(_, command, model, tokenizer, max_sequence_length):\n",
    "    prediction = predict_class(command, tokenizer, model, max_sequence_length)\n",
    "    return [\"Battery Fuel\", \"Tires\", \"Greetings\", \"Basic\"][prediction] if prediction < 4 else \"Unknown\"\n",
    "\n",
    "def Cloud_Model(_, command, model, tokenizer, max_sequence_length):\n",
    "    prediction = predict_class(command, tokenizer, model, max_sequence_length)\n",
    "    return [\"Song Media\", \"News Notification\", \"Weather\", \"Traffic Maps\"][prediction] if prediction < 4 else \"Unknown\"\n",
    "\n",
    "def Update_Model(_, command, model, tokenizer, max_sequence_length):\n",
    "    prediction = predict_class(command, tokenizer, model, max_sequence_length)\n",
    "    return [\"Cancel\", \"Perform\", \"Check\"][prediction] if prediction < 3 else \"Unknown\"\n",
    "\n",
    "def Main_model(_, command):\n",
    "    prediction = predict_class(command, tokenizer, model, max_sequence_length)\n",
    "    if prediction == 0:\n",
    "        return [\"Edge\", Edge_Model(_, command, model_E, tokenizer_E, max_sequence_length_E)]\n",
    "    elif prediction == 1:\n",
    "        return [\"Cloud\", Cloud_Model(_, command, model_C, tokenizer_C, max_sequence_length_C)]\n",
    "    elif prediction == 2:\n",
    "        return [\"Update\", Update_Model(_, command, model_U, tokenizer_U, max_sequence_length_U)]\n",
    "    elif prediction == 3:\n",
    "        return [\"Miscellaneous\", \"Temporary\"]\n",
    "    return [\"Unknown\", \"Unknown\"]\n",
    "\n",
    "def sunamdha(command):\n",
    "    pipeline = joblib.load('./app/Server/Models/ClassSvm.joblib')\n",
    "    df = pd.DataFrame({'Commands': [command]})\n",
    "    return pipeline.predict(df['Commands'])[0]\n",
    "\n",
    "def commandClassify_Sunamdha(class_label_to_predict, text_result):\n",
    "    df = pd.DataFrame({'Commands': [text_result]})\n",
    "    if class_label_to_predict in ['Miscellaneous']:\n",
    "        predicted_subclass = ['Temporary']\n",
    "    elif class_label_to_predict in ['Not needed']:\n",
    "        predicted_subclass = ['NC']\n",
    "    else:\n",
    "        model_path = f'./app/Server/Models/SubClassModel_{class_label_to_predict}.joblib'\n",
    "        subClassModel = joblib.load(model_path)\n",
    "        predicted_subclass = subClassModel.predict(df['Commands'])\n",
    "    return [class_label_to_predict, predicted_subclass[0]]\n",
    "\n",
    "def commandClassifier(command):\n",
    "    subclasscat = \"MAINMODEL\"\n",
    "    opLst = Main_model(subclasscat, command)\n",
    "    subclass_cat = commandClassify_Sunamdha(opLst[0], command)\n",
    "    return [opLst[0], subclass_cat[1], 0, 0]  # timing skipped for simplicity\n",
    "def SRSR(username, command_file):\n",
    "    try:\n",
    "        dyn_thre = None\n",
    "        with open(\"app/Server/dynamic-content/dynamicThreshold.txt\", \"r\") as f:\n",
    "            for line in f:\n",
    "                uname, value = line.strip().split(\": \")\n",
    "                if uname == username:\n",
    "                    dyn_thre = torch.tensor(float(value.replace('tensor([', '').replace('])', '')))\n",
    "                    break\n",
    "\n",
    "        if dyn_thre is None:\n",
    "            print(\"Dynamic threshold not found for user.\")\n",
    "            return False\n",
    "\n",
    "        ref_path = None\n",
    "        with open(\"app/Server/dynamic-content/users.txt\", \"r\") as f:\n",
    "            for line in f:\n",
    "                uname, path = line.strip().split(\": \")\n",
    "                if uname == username:\n",
    "                    ref_path = path.strip()\n",
    "                    break\n",
    "\n",
    "        if not ref_path or not os.path.exists(ref_path):\n",
    "            print(\"Reference file not found.\")\n",
    "            return False\n",
    "\n",
    "        # Step 1 - Direct verification\n",
    "        ref_path=ref_path.replace(\"\\\\\", \"/\")\n",
    "        score, _ = verification.verify_files(ref_path, command_file)\n",
    "        score = score.item()\n",
    "        print(f\" Direct score = {score:.4f} | Threshold = {dyn_thre}\")\n",
    "\n",
    "        if score >= dyn_thre:\n",
    "            return True\n",
    "        elif score < 0.3:\n",
    "            print(\"Score too low (< 0.3). Rejecting.\")\n",
    "            return False\n",
    "        else:\n",
    "            # Step 2 - Try wake-word merged verification\n",
    "            wake_path = f\"./app/Server/dynamic-content/heyTVS/{username}_heyTVS.wav\"\n",
    "            if os.path.exists(wake_path):\n",
    "                user_audio = AudioSegment.from_wav(wake_path)\n",
    "                cmd_audio = AudioSegment.from_wav(command_file)\n",
    "                merged = user_audio + cmd_audio\n",
    "                merged_path = \"./app/Server/dynamic-content/unknownVoices/merged_audio_heyTVS.wav\"\n",
    "                merged.export(merged_path, format=\"wav\")\n",
    "\n",
    "                score2, _ = verification.verify_files(ref_path, merged_path)\n",
    "                score2 = score2.item()\n",
    "                print(f\" Merged score = {score2:.4f}\")\n",
    "\n",
    "                if score2 >= dyn_thre or score2 >= 0.7:\n",
    "                    return True\n",
    "                else:\n",
    "                    return False\n",
    "            else:\n",
    "                print(\"Wake word audio not found.\")\n",
    "                return False\n",
    "    except Exception as e:\n",
    "        print(f\"Error in SRSR: {e}\")\n",
    "        return False\n",
    "def register():\n",
    "    base_path = \"./app/Server/dynamic-content\"\n",
    "    users_file_path = os.path.join(base_path, \"users.txt\")\n",
    "    names_file_path = os.path.join(base_path, \"names.txt\")\n",
    "    standard_path = os.path.join(base_path, \"final_standard\")\n",
    "    predict_temp_path = os.path.join(base_path, \"predictTemp\")\n",
    "\n",
    "    wake_path = os.path.join(base_path, \"heyTVS\")\n",
    "    wake_file_path = os.path.join(base_path, \"heyTVS.txt\")\n",
    "\n",
    "    command_folder_path = os.path.join(base_path, \"commands\")\n",
    "    command_text_file = os.path.join(base_path, \"commands.txt\")\n",
    "    threshold_file_path = os.path.join(base_path, \"dynamicThreshold.txt\")\n",
    "\n",
    "    speak(\"Please say your name\")\n",
    "    username = input(\"Enter username: \").strip()\n",
    "\n",
    "    if not username:\n",
    "        speak(\"Username cannot be empty\")\n",
    "        return\n",
    "\n",
    "    if os.path.exists(names_file_path):\n",
    "        with open(names_file_path, \"r\") as file:\n",
    "            existing_names = [line.strip().lower() for line in file]\n",
    "        if username.lower() in existing_names:\n",
    "            speak(\"Username already exists. Please try a different name.\")\n",
    "            return\n",
    "\n",
    "    user_audio_path = os.path.join(standard_path, f\"{username}.wav\")\n",
    "    user_audio_predict_path = os.path.join(predict_temp_path, f\"{username}_predict.wav\")\n",
    "    wake_audio_filename = f\"{username}_heyTVS.wav\"\n",
    "    wake_audio_path = os.path.join(wake_path, wake_audio_filename)\n",
    "    command_audio_filename = f\"{username}_command.wav\"\n",
    "    command_audio_path = os.path.join(command_folder_path, command_audio_filename)\n",
    "    relative_wake_path = f\"dynamic-content/heyTVS/{wake_audio_filename}\"\n",
    "    relative_command_path = f\"app/Server/dynamic-content/commands/{command_audio_filename}\"\n",
    "\n",
    "    speak(\"Recording reference audio\")\n",
    "    sleep(1)\n",
    "    record_audio(user_audio_path)\n",
    "\n",
    "    speak(\"Recording verification audio\")\n",
    "    sleep(1)\n",
    "    record_audio(user_audio_predict_path)\n",
    "\n",
    "    try:\n",
    "        score, _ = verification.verify_files(user_audio_path, user_audio_predict_path)\n",
    "        score = score.item()\n",
    "        print(user_audio_path, user_audio_predict_path)\n",
    "        print(f\"Verification score: {score:.4f}\")\n",
    "\n",
    "        if score >= 0.7:\n",
    "            with open(users_file_path, \"a\") as ufile:\n",
    "                ufile.write(f\"{username}: {user_audio_path}\\n\")\n",
    "            with open(names_file_path, \"a\") as nfile:\n",
    "                nfile.write(f\"{username}\\n\")\n",
    "\n",
    "            record_audio(wake_audio_path, duration=2, audioName=\"HeyTvs\")\n",
    "            with open(wake_file_path, \"a\") as wfile:\n",
    "                wfile.write(f\"{username}: {relative_wake_path}\\n\")\n",
    "\n",
    "            # Command recording phase\n",
    "            command_attempts = 0\n",
    "            max_attempts = 8\n",
    "            command_verified = False\n",
    "            cmd_score = 0.0  # initialize to avoid reference error\n",
    "\n",
    "            # Define versions of the command\n",
    "            very_short_command = \"Weather in Bangalore\"\n",
    "            short_command = \"Current weather in Bangalore\"\n",
    "            default_command = \"Current weather in Bangalore is very nice?\"\n",
    "            long_command = \"Current weather in Bangalore is very nice today and I love it\"\n",
    "            very_long_command = \"Current weather in Bangalore is very nice today, I love the temperature and climate so much\"\n",
    "\n",
    "            while command_attempts < max_attempts and not command_verified:\n",
    "                # Choose prompt based on previous score\n",
    "                if command_attempts == 0:\n",
    "                    current_prompt = default_command\n",
    "                else:\n",
    "                    if cmd_score < 0.45:\n",
    "                        current_prompt = very_long_command\n",
    "                    elif cmd_score < 0.475:\n",
    "                        current_prompt = long_command\n",
    "                    elif cmd_score > 0.65:\n",
    "                        current_prompt = very_short_command\n",
    "                    elif cmd_score > 0.6:\n",
    "                        current_prompt = short_command\n",
    "                    else:\n",
    "                        current_prompt = default_command\n",
    "\n",
    "                speak(f\"Please say the command: '{current_prompt}'\")\n",
    "                sleep(1)\n",
    "                record_audio(command_audio_path, duration=5)\n",
    "\n",
    "                try:\n",
    "                    cmd_score, _ = verification.verify_files(user_audio_path, command_audio_path)\n",
    "                    cmd_score = cmd_score.item()\n",
    "                    print(f\"Command match score: {cmd_score:.4f}\")\n",
    "\n",
    "                    if 0.475 <= cmd_score <= 0.6:\n",
    "                        with open(command_text_file, \"a\") as cfile:\n",
    "                            cfile.write(f\"{username}: {relative_command_path}\\n\")\n",
    "                        with open(threshold_file_path, \"a\") as tfile:\n",
    "                            tfile.write(f\"{username}: tensor([{cmd_score:.4f}])\\n\")\n",
    "\n",
    "                        command_verified = True\n",
    "                        speak(f\"Registration successful for {username}\")\n",
    "                        break\n",
    "                    else:\n",
    "                        speak(\"Command does not match. Retrying with adjusted prompt...\")\n",
    "                        command_attempts += 1\n",
    "\n",
    "                except Exception as e:\n",
    "                    speak(f\"Error verifying standard command: {str(e)}\")\n",
    "                    command_attempts += 1\n",
    "\n",
    "            if not command_verified:\n",
    "                speak(\"Registration failed due to repeated command mismatch. Cleaning up.\")\n",
    "                cleanup_user_data(username, [\n",
    "                    user_audio_path,\n",
    "                    user_audio_predict_path,\n",
    "                    wake_audio_path,\n",
    "                    command_audio_path\n",
    "                ], [\n",
    "                    users_file_path,\n",
    "                    names_file_path,\n",
    "                    wake_file_path,\n",
    "                    command_text_file,\n",
    "                    threshold_file_path\n",
    "                ])\n",
    "\n",
    "        else:\n",
    "            speak(\"Voice match failed. Registration unsuccessful.\")\n",
    "            if os.path.exists(user_audio_path):\n",
    "                os.remove(user_audio_path)\n",
    "            if os.path.exists(user_audio_predict_path):\n",
    "                os.remove(user_audio_predict_path)\n",
    "\n",
    "    except Exception as e:\n",
    "        speak(f\"Error during registration: {str(e)}\")\n",
    "        if os.path.exists(user_audio_path):\n",
    "            os.remove(user_audio_path)\n",
    "        if os.path.exists(user_audio_predict_path):\n",
    "            os.remove(user_audio_predict_path)\n",
    "\n",
    "# Helper: Remove user entries and files\n",
    "def cleanup_user_data(username, file_paths, text_files):\n",
    "    for file_path in file_paths:\n",
    "        if os.path.exists(file_path):\n",
    "            os.remove(file_path)\n",
    "\n",
    "    def remove_line(file, key):\n",
    "        if os.path.exists(file):\n",
    "            with open(file, \"r\") as f:\n",
    "                lines = f.readlines()\n",
    "            with open(file, \"w\") as f:\n",
    "                for line in lines:\n",
    "                    if not line.lower().startswith(key.lower()):\n",
    "                        f.write(line)\n",
    "\n",
    "    for txt_file in text_files:\n",
    "        remove_line(txt_file, username)\n",
    "\n",
    "\n",
    "def login():\n",
    "    user_file_path = \"./app/Server/dynamic-content/users.txt\"\n",
    "    speak(\"Recording login audio\")\n",
    "    sleep(1)\n",
    "    record_audio(\"./app/Server/dynamic-content/unknownVoices/unknown.wav\")\n",
    "\n",
    "    user_scores = {}\n",
    "    if not os.path.exists(user_file_path):\n",
    "        speak(\"User reference file not found.\")\n",
    "        return\n",
    "\n",
    "    with open(user_file_path, \"r\") as file:\n",
    "        for line in file:\n",
    "            if ':' in line:\n",
    "                name, ref_path = line.strip().split(':', 1)\n",
    "                name, ref_path = name.strip(), ref_path.strip()\n",
    "                if os.path.exists(ref_path):\n",
    "                    try:\n",
    "                        ref_path=ref_path.replace(\"\\\\\", \"/\")\n",
    "                        score, _ = verification.verify_files(ref_path, \"./app/Server/dynamic-content/unknownVoices/unknown.wav\")\n",
    "                        x=\"./app/Server/dynamic-content/unknownVoices/unknown.wav\"\n",
    "                        print(score.item(),ref_path,x)\n",
    "                        user_scores[name] = score.item()\n",
    "                        print(f\"Score for {name}: {score}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing {name}: {e}\")\n",
    "                else:\n",
    "                    print(f\"Reference audio not found for {name}: {ref_path}\")\n",
    "\n",
    "    if user_scores:\n",
    "        best_match = max(user_scores, key=user_scores.get)\n",
    "        max_score = user_scores[best_match]\n",
    "\n",
    "        if max_score >= 0.7:\n",
    "            speak(f\"Welcome {best_match} to OTA Voice Assistant\")\n",
    "            while True:\n",
    "                speak(\"Listening for a wake word: 'Hey Bike'\")\n",
    "                record_audio(\"temp_trigger.wav\", duration=3)\n",
    "                keyword = transcribe_google(\"temp_trigger.wav\")\n",
    "                print(f\"Recognized keyword: {keyword}\")\n",
    "\n",
    "                if \"logout\" in keyword:\n",
    "                    speak(\"Logging out. Goodbye!\")\n",
    "                    break\n",
    "\n",
    "                elif \"hey bike\" in keyword:\n",
    "                    speak(\"How can I help you?\")\n",
    "                    input_cmd_path = \"./app/Server/dynamic-content/inputCmd/inputCmd.wav\"\n",
    "                    record_audio(input_cmd_path, duration=5)\n",
    "                    command = transcribe_google(input_cmd_path)\n",
    "                    print(f\"User command: {command}\")\n",
    "\n",
    "                    # ✅ Verify speaker before classification\n",
    "                    if SRSR(best_match, input_cmd_path):\n",
    "                        # LSTM Prediction\n",
    "                        anirban_main, anirban_sub, _, _ = commandClassifier(command)\n",
    "                        print(f\"Anirban ➤ Main: {anirban_main}, Sub: {anirban_sub}\")\n",
    "\n",
    "                        # SVM Prediction\n",
    "                        svm_main = sunamdha(command)\n",
    "                        svm_main, svm_sub = commandClassify_Sunamdha(anirban_main, command)\n",
    "                        print(f\"Sunamdha ➤ Main: {svm_main}, Sub: {svm_sub}\")\n",
    "\n",
    "                        speak(f\"Command recoginized as {anirban_main} with subcategory {svm_sub}\")\n",
    "                    else:\n",
    "                        speak(\"Speaker verification failed. Please say 'Hey Bike' again.\")\n",
    "                else:\n",
    "                    speak(\"Unrecognized command. Please say 'Logout' to exit the session.\")\n",
    "        else:\n",
    "            speak(\"Unauthorized user\")\n",
    "    else:\n",
    "        speak(\"No valid users found for verification\")\n",
    "\n",
    "def main():\n",
    "    print(\"Select an option:\")\n",
    "    print(\"1. Register\")\n",
    "    print(\"2. Login\")\n",
    "    print(\"3. Exit\")\n",
    "   \n",
    "    choice = input(\"Enter your choice (1/2/3): \")\n",
    "\n",
    "    switch = {\n",
    "        \"1\": register,\n",
    "        \"2\": login,\n",
    "        \"3\":  lambda: (_ for _ in ()).throw(SystemExit)\n",
    "    }\n",
    "\n",
    "    action = switch.get(choice)\n",
    "   \n",
    "    if action:\n",
    "        action()\n",
    "    else:\n",
    "        print(\"Invalid choice. Please select 1 or 2.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    while(1):\n",
    "        main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
